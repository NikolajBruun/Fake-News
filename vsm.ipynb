{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer  # Til tekstbehandling\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import accuracy_score, classification_report, f1_score\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('cleanedStemmedCATbbc2.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "broad_category\n",
       "Fake News        43590\n",
       "Reliable News    41247\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['broad_category'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df['content'], df['broad_category'], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "X_train_vec og X_test_vec indeholder tekst nemlig 'content'.\n",
    "Ved brug af modulet 'TfidfVectorizer' kan vi omdanne hver tekst til en række af vægtede tal baseret på TF-IDF (Term Frequency-Inverse Document Frequency).\n",
    "- Term Frequency (TF): Hvor ofte et ord optræder i en given tekst.\n",
    "- Inverse Document Frequency (IDF): Hvor sjældent ordet optræder på tværs af alle dokumenter – jo sjældnere, desto vigtigere."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vektoriser tekstdata (TF-IDF)\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_train_vec = vectorizer.fit_transform(X_train)\n",
    "X_test_vec = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(67869, 348321)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_vec.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dette betyder at vi har 67869 tekster og 348321 unikke ord."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 154757)\t0.692729182306506\n",
      "  (0, 179957)\t0.1811974802545005\n",
      "  (0, 167945)\t0.3418501081670975\n",
      "  (0, 279436)\t0.13908135981551245\n",
      "  (0, 61642)\t0.15374907561930365\n",
      "  (0, 178328)\t0.09524172983917649\n",
      "  (0, 321903)\t0.08309029399705253\n",
      "  (0, 246848)\t0.15347423413731567\n",
      "  (0, 338081)\t0.11252975595183769\n",
      "  (0, 95720)\t0.22311495969615974\n",
      "  (0, 224941)\t0.18219722195171578\n",
      "  (0, 319791)\t0.16713534710957997\n",
      "  (0, 215972)\t0.17041804350934242\n",
      "  (0, 286813)\t0.2118149311476041\n",
      "  (0, 68009)\t0.1351946216338627\n",
      "  (0, 254829)\t0.14195269630850751\n",
      "  (0, 310451)\t0.22805968012240363\n"
     ]
    }
   ],
   "source": [
    "print(X_train_vec[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Forklaring af outputtet når teksten er blevet nummeriseret:\n",
    "Eksempel på output: \n",
    "(0, 2394)\t0.09388827930025204\n",
    "\n",
    "Række (0): Angiver, at vi ser på den første tekst i datasættet.\n",
    "Kolonne (2394): Hver kolonne repræsenterer en unik funktion (ord) i vokabularet.\n",
    "Værdi (0.0939 osv.): TF-IDF-vægten – en højere værdi betyder, at ordet er vigtigere i denne tekst i forhold til resten af korpuset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy: 86.33%\n",
      "Model F1-score: 0.86\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Træn SVM-model\n",
    "model = LinearSVC(class_weight='balanced',C=0.8, dual=False, max_iter=10000)\n",
    "model.fit(X_train_vec, y_train)\n",
    "\n",
    "# Forudsig på testdata\n",
    "y_pred = model.predict(X_test_vec)\n",
    "\n",
    "# Evaluer præstation\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred, average='weighted') \n",
    "print(f\"Model accuracy: {accuracy * 100:.2f}%\")\n",
    "print(f\"Model F1-score: {f1:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: Fake News\n",
      "Prediction: Reliable News\n",
      "Prediction: Fake News\n",
      "Prediction: Reliable News\n"
     ]
    }
   ],
   "source": [
    "# Funktion til at forudsige om en nyhed er fake eller ægte\n",
    "def predict_news(news_text):\n",
    "    news_vec = vectorizer.transform([news_text])  # Vektoriser ny tekst\n",
    "    prediction = model.predict(news_vec)          # Forudsig\n",
    "    return prediction[0]\n",
    "\n",
    "#Conspiracy\n",
    "new_article = \"\"\"\n",
    "look like your use ad blocker pleas whitelist disabl abovetopsecretcom adblock tool thank\n",
    "\"\"\"\n",
    "\n",
    "result = predict_news(new_article)\n",
    "print(f\"Prediction: {result}\")\n",
    "\n",
    "#Reliable\n",
    "new_article2 =\"\"\"editor suppos let iran bomb week review march unit state iran share interest iraq stabil well afghanistan must work togeth contain present iraqi nose dive toward civil war turn requir mutual moratorium side demon side disallow incendiari rhetor supplant prudent foreign policymak doubtless good gener result success dialogu iraq extend larger issu region secur like even motiv iran endors call gulf cooper council persian gulf nuclearweaponsfre zone kaveh l afrasiabi cambridg mass writer former advis iran nuclear negoti team author book iran nuclear program\"\"\"\n",
    "result2 = predict_news(new_article2)\n",
    "print(f\"Prediction: {result2}\")\n",
    "\n",
    "#Political1\n",
    "new_article3=\"\"\"convict fraudster former pharmaceut compani ceo martin shkreli dub hate man america head jail bail revok facebook post offer cur strand hillari clinton hair us district judg kiyo matsumoto rule wednesday shkreli\"\"\"\n",
    "print(f\"Prediction: {predict_news(new_article3)}\")\n",
    "\n",
    "#Political2\n",
    "new_article4=\"\"\"red eye open thread dko list complet hit leadership delay blunt hit swing state hit toptier race knowl stork murphi embrac famili seemann newberri david vs goliath two well morrison target race verg toptier\"\"\"\n",
    "print(f\"Prediction: {predict_news(new_article4)}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
